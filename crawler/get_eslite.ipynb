{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://www.eslite.com/Search_BW.aspx?query={keyword}&searchType=&page={page}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀取資料\n",
    "with open('eslite2.txt', 'r',encoding='utf-8') as fp:\n",
    "    data = eval(fp.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 儲存資料\n",
    "with open('eslite2.txt', 'w',encoding='utf-8') as fp:\n",
    "    fp.write(str(data))\n",
    "    isSave = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "isSave = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword =  [f\"%E6%BC%94%E7%AE%97%E6%B3%95\", f\"%E7%B7%9A%E6%80%A7%E4%BB%A3%E6%95%B8\", '%E5%AF%B5%E7%89%A9', '%E4%BC%91%E9%96%92', '%E4%BF%9D%E5%81%A5', '%E9%86%AB%E7%BE%8E', '3C']\n",
    "# 演算法, 線性, 寵物, 休閒, 保健, 醫美, 3C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2703"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['%E5%8B%95%E7%89%A9',\n",
       " '%E9%9B%BB%E8%85%A6',\n",
       " '%E7%A7%91%E6%8A%80',\n",
       " '%E7%A7%91%E5%AD%B8',\n",
       " '%E9%9B%BB%E5%AD%90']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requests -> 200\n",
      "requests -> 200\n",
      "requests -> 200\n",
      "requests -> 200\n",
      "requests -> 200\n",
      "requests -> 200\n",
      "requests -> 200\n",
      "requests -> 200\n",
      "requests -> 200\n",
      "requests -> 200\n",
      "requests -> 200\n",
      "requests -> 200\n",
      "requests -> 200\n",
      "requests -> 200\n",
      "requests -> 200\n",
      "requests -> 200\n",
      "requests -> 200\n",
      "requests -> 200\n",
      "requests -> 200\n",
      "requests -> 200\n",
      "requests -> 200\n",
      "requests -> 200\n",
      "requests -> 200\n",
      "requests -> 200\n",
      "requests -> 200\n",
      "requests -> 200\n",
      "requests -> 200\n",
      "requests -> 200\n",
      "requests -> 200\n",
      "requests -> 200\n",
      "requests -> 200\n",
      "requests -> 200\n",
      "requests -> 200\n",
      "requests -> 200\n",
      "requests -> 200\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    isSave = False\n",
    "    for key in keyword:\n",
    "        for page in range(6, 11): # 2~last page   #初始值~終點值-1\n",
    "            try:\n",
    "                tmp_url = url.format(keyword=key, page=page)\n",
    "                soup = getHtml(method='get', url=tmp_url)\n",
    "                if soup!=None:\n",
    "                    try:\n",
    "                        item_soup = soup.find('div', id='search_content').find_all('table', {\"border\":0})\n",
    "                        for i in item_soup:\n",
    "                            index = i.find('h3').a['href'].split('pgid=')[-1]\n",
    "                            title_img = i.img\n",
    "                            info = i.find('td', class_='summary').find_all('span')\n",
    "\n",
    "                            data[index] = {\n",
    "                                    'imgURL':title_img['src'].strip(),\n",
    "                                    'title':title_img['alt'].strip(),\n",
    "                                    'price':i.find('td', class_='summary').find('font').text.strip(),\n",
    "                                    'date':info[2].text.strip().split(':')[-1].strip(),\n",
    "                                    'author':info[0].text.strip(),\n",
    "                                    'pub':info[1].text.strip()  \n",
    "                                }\n",
    "                    except:\n",
    "                        print('process error')\n",
    "                        history.append({'status':'process','key':key, 'page':page})\n",
    "                else:\n",
    "                    print('soup none')\n",
    "                    history.append({'status':'soup none','key':key, 'page':page})\n",
    "                    \n",
    "            except:\n",
    "                print('error')\n",
    "                history.append({'key':key, 'page':page})\n",
    "            time.sleep(0.5)\n",
    "        time.sleep(120)\n",
    "except KeyboardInterrupt:\n",
    "    print('KeyboardInterrupt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requests -> 200\n"
     ]
    }
   ],
   "source": [
    "url = \"http://www.eslite.com/Search_BW.aspx?query=python&searchType=&page=1\"\n",
    "soup = getHtml(method= 'get', url = url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re, requests, json, time\n",
    "def getHtml(method, url, params= None, data= None, encoding= 'utf-8'):\n",
    "    try:\n",
    "        headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.198 Safari/537.36 Edg/86.0.622.69\"}\n",
    "        if method == 'get':\n",
    "            req = requests.get(url, headers= headers, params= params)\n",
    "        elif method == 'post':\n",
    "            req = requests.post(url, headers= headers, data= data)\n",
    "        if req.status_code == 200:\n",
    "            print('requests -> 200')\n",
    "            req.encoding = encoding\n",
    "            return BeautifulSoup(req.text, 'html.parser')\n",
    "        print('requests -> ', req.status_code)\n",
    "        return None\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data ={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requests -> 200\n",
      "requests -> 200\n",
      "requests -> 200\n",
      "requests -> 200\n",
      "requests -> 200\n"
     ]
    }
   ],
   "source": [
    "current = {\n",
    "    'index':None,\n",
    "    'page':None\n",
    "}\n",
    "isSave = False\n",
    "for page in range(30, 35): # 2~last page   #初始值~終點值-1\n",
    "    tmp_url = url.format(keyword='python', page=page)\n",
    "    soup = getHtml(method='get', url=tmp_url)\n",
    "    if soup!=None:\n",
    "        item_soup = soup.find('div', id='search_content').find_all('table', {\"border\":0})\n",
    "        for i in item_soup:\n",
    "            index = i.find('h3').a['href'].split('pgid=')[-1]\n",
    "            title_img = i.img\n",
    "            info = i.find('td', class_='summary').find_all('span')\n",
    "\n",
    "            data[index] = {\n",
    "                    'imgURL':title_img['src'].strip(),\n",
    "                    'title':title_img['alt'].strip(),\n",
    "                    'price':i.find('td', class_='summary').find('font').text.strip(),\n",
    "                    'date':info[2].text.strip().split(':')[-1].strip(),\n",
    "                    'author':info[0].text.strip(),\n",
    "                    'pub':info[1].text.strip()  \n",
    "                }\n",
    "    else:\n",
    "        print('soup none')\n",
    "    time.sleep(0.5)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
