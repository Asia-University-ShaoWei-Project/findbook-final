{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "# import requests_async as requests\n",
    "from fake_useragent import UserAgent\n",
    "# import asyncio\n",
    "def getHtml(method, url, params= None, data= None, encoding= 'utf-8'):\n",
    "    try:\n",
    "    # headers = {'user-agent':\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.130 Safari/537.36\"}\n",
    "    # req = requests.request(req_type, url, data)\n",
    "        headers = {'user-agent':str(UserAgent().random)}\n",
    "\n",
    "        if method == 'get':\n",
    "            req = requests.get(url, headers= headers, params= params)\n",
    "        elif method == 'post':\n",
    "            req = requests.post(url, headers= headers, data= data)\n",
    "            \n",
    "        # req=requests.get(url, headers= headers, params= params)\n",
    "        if req.status_code == 200:\n",
    "            print('requests -> 200')\n",
    "            req.encoding = encoding\n",
    "            return BeautifulSoup(req.text, 'html.parser')\n",
    "        print('requests -> ', req.status_code)\n",
    "        return None\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "def textClean(splitChar='', text='', loop=1, reRight=True, notReverse = True): #\n",
    "    myIndex = 1 if notReverse else 0\n",
    "    myLoop = 0\n",
    "    myRange = text if notReverse else reversed(text)\n",
    "    for i in myRange:\n",
    "        if i == splitChar: \n",
    "            myLoop+=1\n",
    "            if myLoop==loop: \n",
    "                if reRight:\n",
    "                    return text[myIndex:] if notReverse else text[-myIndex:] # 由index至右\n",
    "                return text[:myIndex] if notReverse else text[:-myIndex] # 由左至index\n",
    "        myIndex+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanmin(soup, infoData):\n",
    "    # --- Price ---  (簡單暴力法, 待修改)\n",
    "    str1 = soup.find('script', {'type':'application/ld+json'}).contents[0].strip()\n",
    "    data = json.loads(str1)\n",
    "    data['offers']['price']\n",
    "    # --- image URL ---\n",
    "    # 書封面 cdnec.sanmin.com.tw/product_images/\n",
    "    # other cdnec.sanmin.com.tw/tryread/big/\n",
    "    tmp = soup.find('div', class_='gallery-top').findAll('div', class_='swiper-slide')   # 大圖示欄\n",
    "    imgURL = [tmp[0].img['src'][37:]]  # first img \n",
    "    imgURL.extend([i.img['src'][40:] for i in tmp[1:]])  # other img\n",
    "    # --- Information ---\n",
    "    tag = {'書名':'title','ISBN':'isbn','頁數':'page','出版社':'pub','作者':'author', '出版日期':'date'}\n",
    "    findInfo = soup.find('meta', {'name':'description'})['content']\n",
    "    for i in findInfo.split('，'):  # book info處理\n",
    "        tmp =  i.split('：')\n",
    "        if len(tmp)>2: tmp = [tmp[0], textClean(splitChar='：', text=i, loop=1)] # 標題, 內容(防止內容出現':'有問題)\n",
    "        key = tag[tmp[0]] if (tmp[0] in tag) else None # 確標籤有在需求(tag)裡\n",
    "        if key: infoData[key] = tmp[1]  # 資料內容\n",
    "    # --- Intr ---\n",
    "    # 標籤 ---\n",
    "    tag = {\n",
    "        \"商品簡介\": 'intr',\n",
    "        \"作者簡介\": 'author',\n",
    "        \"目次\": 'contents',\n",
    "    }\n",
    "    tabTitle_find = soup.findAll('div', class_='tab2')\n",
    "    intrData = [{\"title\": None, \"content\": None} for i in range(len(tabTitle_find))]\n",
    "    for index, i in enumerate(tabTitle_find):\n",
    "        tmp = i.text.strip()  # ex: 商品簡介\n",
    "        intrData[index]['title'] = tag[tmp] if (tmp in tag) else None  # ex: intr, else-> None \n",
    "    # 內容 ---    \n",
    "    contents_find = soup.findAll('div', class_='productContent')\n",
    "    for indexI, i in enumerate(contents_find):\n",
    "        word = ''\n",
    "        for j in i:\n",
    "            tmp = j.string\n",
    "            # if text is None -> loop data get string then join '\\n' \n",
    "            word += f'\\n{tmp}\\n' if tmp!=None else \"\\n\".join([k.string for k in j if k.string!=None])+'\\n'\n",
    "        intrData[indexI]['content'] = word\n",
    "    return {\n",
    "        'imgURL': imgURL,\n",
    "        'info': infoData,\n",
    "        'intr': intrData,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requests -> 200\n"
     ]
    }
   ],
   "source": [
    "soup = getHtml(method='get',url='https://www.sanmin.com.tw/Product/index/005135055')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tmp = soup.find('div', class_='gallery-top')\n",
    "if tmp:\n",
    "    tmp = tmp.findAll('div', class_='swiper-slide')   # 大圖示欄\n",
    "    # //cdnec.sanmin.com.tw/product_images/986/986502596.jpg\n",
    "    imgURL = [tmp[0].img['src'].split('product_images/')[-1]]  # first img \n",
    "    # //cdnec.sanmin.com.tw/tryread/small/986/s_986502596_b1.jpg\n",
    "    # //cdnec.sanmin.com.tw/tryread/big/986/986502596_b1.jpg\n",
    "    imgURL.extend([i.img['src'].split('big/')[-1] for i in tmp[1:]])  # other img\n",
    "else:\n",
    "    imgURL = [soup.find('img', class_='mainImg')['src'].split('product_images/')[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['986/986434014.jpg']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgURL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old indexSearch\n",
    "imgURL = []\n",
    "for i in soup.findAll('div', class_=\"swiper-slide\"):\n",
    "    tmp = i.img['src'].split('//cdnec.sanmin.com.tw/')[1]\n",
    "\n",
    "\n",
    "labels = ['商品簡介', '作者簡介', '目次'] # code number\n",
    "labels_ti = ['itIntr', 'auIntr', 'cons'] # labels dict title\n",
    "# item Introduction、author Introduction、table contents\n",
    "myLabels = []\n",
    "boolIndex = []\n",
    "for index, i in enumerate(soup.findAll('div', class_='IntroTab')):\n",
    "    tmp = i.p.text\n",
    "    if tmp in labels:\n",
    "        myLabels.append(labels.index(tmp))\n",
    "        boolIndex.append(index)\n",
    "\n",
    "\n",
    "productContents = soup.findAll('div', class_='productContent')\n",
    "word = {}\n",
    "count = 0\n",
    "for index, product in enumerate(productContents):  # contents(商品簡介、作者簡介...)\n",
    "    if index in boolIndex:\n",
    "        index = labels_ti[myLabels[count]]\n",
    "        word[index] = []  # add (label:[])\n",
    "        find_p = product.findAll('p') #有p 或 沒有([data, data ...] or [])\n",
    "        len_p  = len(find_p)  # p有幾行\n",
    "        mustLoop = True if len_p else False # 若沒p則不需要迴圈抓取\n",
    "        for i in find_p if len_p else product:\n",
    "            if i.find('br'): # 如果內容有br\n",
    "                tmp = []\n",
    "                if mustLoop:\n",
    "                    for j in i:  # p 內容每行檢查\n",
    "                        if str(j) != '<br/>': tmp.append(j.strip())    # 若文字不為br則放入list\n",
    "                else:\n",
    "                    if str(i) != '<br/>': tmp.append(i.strip())    # 若文字不為br則放入list\n",
    "                word[index].append(tmp if len(tmp)>1 else tmp[0].strip())  # 如果清單才一個 則直接取出\n",
    "            else:\n",
    "                tmp = i.text.strip()\n",
    "                if len(tmp): word[index].append(tmp)\n",
    "        count +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4227829000010388\n",
      "1.2715858000010485\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "print(timeit.timeit('[]', number=10**7))\n",
    "print(timeit.timeit('list()', number=10**7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=f'C:/Users/asias/Library/Application/%20Support/Google/Chrome/Default/History'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\asias\\\\Library\\\\Application\\\\%20Support\\\\Google\\\\Chrome\\\\Default\\\\History'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.replace(f'/',f'\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
